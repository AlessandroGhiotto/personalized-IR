{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query expansion with LLMs\n",
    "\n",
    "Armanni Luca - 509085\n",
    "\n",
    "Ghiotto Alessandro - 513944\n",
    "\n",
    "---\n",
    "\n",
    "As first simple personalization method we expand the query with the tags via an LLM, before of feeding it to the biencoder.\n",
    "\n",
    "### Table of contents:\n",
    "- Set up the LLM\n",
    "- Get Tags\n",
    "- Reranking pipeline with query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR COLAB\n",
    "\n",
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "\n",
    "# !conda install -c pytorch faiss-gpu -y\n",
    "\n",
    "# !pip install --upgrade -q python-terrier\n",
    "# !pip install -q sentence_transformers ipdb emoji\n",
    "\n",
    "# !pip install -q flash-attn\n",
    "# !pip install -q quanto optimum-quanto\n",
    "\n",
    "# !gdown 1HhgXzyEpsZNcenU9XhJuOYyDUKEzUse4\n",
    "# !unzip pir_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.10 (build: craigm 2024-08-22 17:33), helper_version=0.0.8]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import faiss\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "# Hugging Face\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, QuantoConfig\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# TEXT PROCESSING\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# TERRIER\n",
    "from pyterrier.measures import *\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.java.started():\n",
    "    pt.utils.set_tqdm('notebook')\n",
    "    pt.java.init()\n",
    "\n",
    "# FILTER WARNINGS\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead\",\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\",\n",
    ")\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# SET SEED\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data in the exact same way as the previous notebook, the only difference is that we keep also the *timestamp* and the *user_id*. timestamps are stored as unix timestamps (time in seconds from January 1st, 1970)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ghi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text, apply_stemmer=False, remove_stopwords=False):\n",
    "    # remove emojis\n",
    "    text = emoji.replace_emoji(text, \"\")\n",
    "    # remove links\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    # remove html tags\n",
    "    # text = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
    "    # lowercase verything\n",
    "    text = text.lower()\n",
    "    # remove backslashes\n",
    "    text = re.sub(r\"\\\\\", \"\", text)\n",
    "    # remove special characters and punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    # remove whitespaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # remove leading and trailing whites\n",
    "    text = text.strip()\n",
    "    # apply spelling correction\n",
    "    # text = TextBlob(text).correct()\n",
    "    tokens = text.split()\n",
    "    if remove_stopwords:\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "    if apply_stemmer:\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWERS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>writers_2010</td>\n",
       "      <td>TL;DRIf you're going to do present tense do it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>writers_2018</td>\n",
       "      <td>Your writing style is stream-of-consciousness,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>writers_2023</td>\n",
       "      <td>Place emphasis on uncomfortable things. Depend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          docno                                               text\n",
       "0  writers_2010  TL;DRIf you're going to do present tense do it...\n",
       "1  writers_2018  Your writing style is stream-of-consciousness,...\n",
       "2  writers_2023  Place emphasis on uncomfortable things. Depend..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERIES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query_unprocessed</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academia_100456</td>\n",
       "      <td>Is there a free (as in freedom) alternative to...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513191752</td>\n",
       "      <td>free freedom altern publon review journal allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academia_103390</td>\n",
       "      <td>Search for StackExchange citations with Google...</td>\n",
       "      <td>1532620</td>\n",
       "      <td>1517935259</td>\n",
       "      <td>search stackexchang citat googl scholar possib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qid                                  query_unprocessed  \\\n",
       "0  academia_100305  What are CNRS research units and how are they ...   \n",
       "1  academia_100456  Is there a free (as in freedom) alternative to...   \n",
       "2  academia_103390  Search for StackExchange citations with Google...   \n",
       "\n",
       "   user_id   timestamp                                              query  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  \n",
       "1  1106095  1513191752  free freedom altern publon review journal allo...  \n",
       "2  1532620  1517935259  search stackexchang citat googl scholar possib...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QRELS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>academia_100217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academia_100456</td>\n",
       "      <td>academia_100462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academia_103390</td>\n",
       "      <td>academia_103391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qid            docno  label\n",
       "0  academia_100305  academia_100217      1\n",
       "1  academia_100456  academia_100462      1\n",
       "2  academia_103390  academia_103391      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COLLECTION OF DOCUMENTS (ANSWERS)\n",
    "def preprocess_corpus(df):\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['docno', 'text']\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df['text_stemmed_stopwords_removed'] = df['text'].apply(lambda x: preprocess_text(x, apply_stemmer=True, remove_stopwords=True))\n",
    "    return df\n",
    "\n",
    "corpus_df = preprocess_corpus(pd.read_json('PIR_data/answer_retrieval/subset_answers.json', orient='index'))\n",
    "\n",
    "# SAMPLES (QUERIES)\n",
    "def preprocess_queries_df(path):\n",
    "    df = pd.read_json(path, lines=True)\n",
    "    df = df[['id', 'text', 'user_id', 'timestamp']]\n",
    "    df.columns = ['qid', 'query_unprocessed', 'user_id', 'timestamp']\n",
    "    df['query'] = df['query_unprocessed'].apply(lambda x: preprocess_text(x, apply_stemmer=True, remove_stopwords=True))\n",
    "    df['timestamp'] = df[\"timestamp\"].astype(int) // 10**9\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "train_queries = preprocess_queries_df('PIR_data/answer_retrieval/train/subset_data.jsonl')\n",
    "val_queries = preprocess_queries_df('PIR_data/answer_retrieval/val/subset_data.jsonl')\n",
    "# test_queries = preprocess_queries_df('PIR_data/answer_retrieval/test/subset_data.jsonl')\n",
    "\n",
    "# QRELS\n",
    "def preprocess_qrels_df(path):\n",
    "    df = pd.read_json(path, orient='index').reset_index()\n",
    "    df.columns = ['qid', 'docno']\n",
    "    df['label'] = 1\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "train_qrels = preprocess_qrels_df('PIR_data/answer_retrieval/train/qrels.json')\n",
    "val_qrels = preprocess_qrels_df('PIR_data/answer_retrieval/val/qrels.json')\n",
    "# test_qrels = preprocess_qrels_df('PIR_data/answer_retrieval/test/qrels.json')\n",
    "\n",
    "print(\"ANSWERS\")\n",
    "display(corpus_df.head(3))\n",
    "print(\"QUERIES\")\n",
    "display(train_queries.head(3))\n",
    "print(\"QRELS\")\n",
    "display(train_qrels.head(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Set up the LLM\n",
    "\n",
    "As first personalization method we expand the query with a LLM. We give as input the orginal query and we ask the model to personalize it given the insterest of the users. The interest of the users at a time *t* are given by the set of tags from all the questions that the user has written before the time *t* (the current question is included).\n",
    "\n",
    "As LLM we use ['Phi-3-mini-4k-instruct'](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct). We quantize it for resources limitations.\n",
    "\n",
    "NOTES on [Quantization](https://huggingface.co/docs/transformers/main//quantization):\n",
    "\n",
    "- Quantization techniques focus on representing data with less information while also trying to not lose too much accuracy. This often means converting a data type to represent the same information with fewer bits.\n",
    "\n",
    "- `\"microsoft/Phi-3-mini-4k-instruct\"` have 3.82B params. With 8-bit quantization, the model should only need around 3.82B params * 1 byte (=8 bit) = 3.8GB. which is the half of the GPU resources needed for using the model without quantizing the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf546698111944aeba27fcb48b8ff874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# QUANTO CONFIG\n",
    "quantization_config = QuantoConfig(weights=\"int8\")\n",
    "\n",
    "# MODEL\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    #\"max_new_tokens\": 256,\n",
    "    \"do_sample\": False, # Deterministic decoding\n",
    "    # \"temperature\": 0.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT   : Given the user interests as comma separated values and the query, provide an expanded version of the query with personalized interests. Just say New Query: and put the generated query. Do non mention anything else. Keywords: medicins, cats Query: I like petting cats, but I am allergic, what should I do? \n",
      "USER INTERESTS : medicins, cats\n",
      "OUTPUT         : New Query: I enjoy petting cats, but I have allergies, what are some hypoallergenic cat breeds I can consider?\n",
      "\n",
      "==================================================\n",
      "\n",
      "INPUT PROMPT   : Given the user interests as comma separated values and the query, provide an expanded version of the query with personalized interests. Just say New Query: and put the generated query. Do non mention anything else. Keywords: no-vax, cats Query: I like petting cats, but I am allergic, what should I do? \n",
      "USER INTERESTS : no-vax, cats\n",
      "OUTPUT         : New Query: I enjoy petting cats, but I have allergies, what are some hypoallergenic cat breeds I can consider?\n"
     ]
    }
   ],
   "source": [
    "# We put user interest before of the query, so aren't cutted off\n",
    "\n",
    "user_interests = {'cats', 'medicins'}\n",
    "user_interests_str = \", \".join(user_interests)\n",
    "query = 'I like petting cats, but I am allergic, what should I do?'\n",
    "prompt = f\"\"\"\n",
    "    Given the user interests as comma separated values and the query,\n",
    "    provide an expanded version of the query with personalized interests.\n",
    "    Just say New Query: and put the generated query. Do non mention anything else.\n",
    "    Keywords: {user_interests_str} Query: {query}\n",
    "\"\"\"\n",
    "prompt = re.sub(r\"\\s+\", \" \", prompt)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(f\"INPUT PROMPT   :{prompt}\")\n",
    "print(f\"USER INTERESTS : {user_interests_str}\")\n",
    "print(f\"OUTPUT         :{output[0]['generated_text']}\")\n",
    "\n",
    "################\n",
    "user_interests = {'cats', 'no-vax'}\n",
    "user_interests_str = \", \".join(user_interests)\n",
    "query = 'I like petting cats, but I am allergic, what should I do?'\n",
    "prompt = f\"\"\"\n",
    "    Given the user interests as comma separated values and the query,\n",
    "    provide an expanded version of the query with personalized interests.\n",
    "    Just say New Query: and put the generated query. Do non mention anything else.\n",
    "    Keywords: {user_interests_str} Query: {query}\n",
    "\"\"\"\n",
    "prompt = re.sub(r\"\\s+\", \" \", prompt)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "output = pipe(messages, **generation_args)\n",
    "print(\"\\n\"+\"=\"*50+\"\\n\")\n",
    "print(f\"INPUT PROMPT   :{prompt}\")\n",
    "print(f\"USER INTERESTS : {user_interests_str}\")\n",
    "print(f\"OUTPUT         :{output[0]['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tags\n",
    "\n",
    "We want to preprocess the Tags in such a way that given a user and the timestamp, we get the set of tags. \n",
    "\n",
    "USERS_TAGS : dictionary associating to each user a list that contains the pair (timestamp, {tags}) for each query. the list is sorted by increasing timestamp.\n",
    "\n",
    "```python\n",
    "USERS_TAGS = {\n",
    "    \"user1_id\": [(t1, {\"tag1\", \"tag2\"}), (t2, {\"tag3\"}), ...],\n",
    "    \"user2_id\": [(t3, {\"tag1\"}), ...],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>{funding, france}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academia_100456</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513191752</td>\n",
       "      <td>{peer-review, open-access}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academia_103390</td>\n",
       "      <td>1532620</td>\n",
       "      <td>1517935259</td>\n",
       "      <td>{citations, google-scholar}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qid  user_id   timestamp                         tags\n",
       "0  academia_100305  1106095  1513009820            {funding, france}\n",
       "1  academia_100456  1106095  1513191752   {peer-review, open-access}\n",
       "2  academia_103390  1532620  1517935259  {citations, google-scholar}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER 1106095 TAGS:\n",
      "[(1341223088, {'software', 'teaching'}), (1343056478, {'conference', 'networking'}), (1343647084, {'publications', 'journals', 'peer-review', 'conference'}), (1343650594, {'publications', 'journals'}), (1346750645, {'paperwork'}), (1349425429, {'publications', 'peer-review'}), (1353929506, {'responsibilities', 'contract'}), (1355405618, {'publications'}), (1359623571, {'job-search'}), (1359655998, {'publications', 'funding'}), (1360500458, {'publications', 'peer-review', 'application'}), (1360586056, {'poster', 'travel'}), (1361798551, {'united-kingdom', 'sexual-misconduct'}), (1362391150, {'seminars', 'etiquette'}), (1363091345, {'career-path', 'working-time', 'sabbatical'}), (1366622104, {'job-search', 'version-control'}), (1367225030, {'ethics', 'peer-review'}), (1370509865, {'copyright', 'creative-commons'}), (1371471877, {'assessment'}), (1375350804, {'writing-style', 'funding', 'writing'}), (1377078634, {'authorship'}), (1379871860, {'faculty-application', 'recommendation-letter'}), (1380631137, {'authorship'}), (1380821299, {'teaching'}), (1387804346, {'job-search'}), (1388146049, {'job-search', 'united-states', 'tenure-track'}), (1389975678, {'publications', 'open-access'}), (1392282649, {'job-search'}), (1394465484, {'cruising'}), (1394708555, {'repatriation', 'usa', 'health-insurance'}), (1394808223, {'united-kingdom', 'usa', 'taxes'}), (1395049854, {'telephone', 'usa'}), (1395138414, {'education', 'usa', 'children', 'repatriation'}), (1395264866, {'united-kingdom', 'citizenship', 'marriage', 'legal'}), (1395309775, {'television'}), (1395741049, {'united-kingdom', 'criminal-records', 'us-citizens'}), (1398807482, {'colleagues'}), (1401660590, {'publications'}), (1403272306, {'disreputable-publishers', 'open-access'}), (1403598266, {'gifts', 'etiquette', 'ethics'}), (1403964864, {'ethics', 'conflict-of-interest'}), (1406646659, {'software', 'copyright', 'graphics'}), (1407436529, {'teaching'}), (1407572885, {'teaching'}), (1410029421, {'postdocs', 'cv'}), (1410516513, {'work-life-balance', 'working-time', 'teaching'}), (1411051600, {'books', 'teaching'}), (1411055405, {'gender', 'sexual-misconduct', 'interpersonal-issues'}), (1411987941, {'syllabus', 'teaching'}), (1412794220, {'united-kingdom', 'health', 'workplace'}), (1412876949, {'gender', 'religious-issues', 'interpersonal-issues', 'ethnicity', 'reference-request'}), (1413557739, {'ethics'}), (1414341713, {'cheating', 'plagiarism'}), (1414343891, {'assessment', 'teaching', 'grading'}), (1414595557, {'funding'}), (1415015726, {'online-learning'}), (1415369795, {'presentation', 'software'}), (1418377606, {'legal-issues'}), (1418753861, {'writing-style', 'website'}), (1418754656, {'degree', 'masters', 'terminology'}), (1420991559, {'salary', 'funding', 'tuition'}), (1420997947, {'tips-and-tricks', 'sleeping'}), (1421004498, {'united-kingdom', 'working-visas'}), (1421004835, {'united-kingdom', 'working-visas'}), (1422525943, {'job-search', 'united-states', 'salary', 'career-path', 'government-institutes'}), (1422890167, {'reputation', 'publications', 'conference', 'computer-science'}), (1422983098, {'plagiarism'}), (1422986986, {'privacy', 'career-path'}), (1423059036, {'graduate-admissions', 'phd', 'united-states', 'canonical-question'}), (1423229504, {'plagiarism', 'ethics'}), (1426514198, {'education', 'working-visas', 'usa'}), (1427104079, {'authorship'}), (1427839634, {'otolaryngology', 'treatment', 'infection'}), (1427840696, {'micronutrients', 'nutrition'}), (1427892888, {'optometry'}), (1429979839, {'personal-name', 'authorship'}), (1430486657, {'commuter', 'bikeroutes'}), (1430672000, {'peer-review'}), (1430839436, {'united-states', 'international', 'united-kingdom', 'home-loan', 'mortgage'}), (1432486019, {'real-estate', 'united-states', 'mortgage', 'primary-residence'}), (1432634559, {'job-search', 'etiquette'}), (1433178274, {'driving-license', 'usa', 'us-citizens'}), (1433178445, {'terminology'}), (1434630323, {'backup-archiving', 'arxiv'}), (1436623288, {'recruiting'}), (1436891607, {'outward-appearance', 'ethics'}), (1441821819, {'bibliometrics'}), (1442155346, {'studs', 'lath-and-plaster', 'partition'}), (1447546386, {'lath-and-plaster', 'trim'}), (1448755184, {'electrical', 'rewire'}), (1454966636, {'backpacking', 'footwear'}), (1455045228, {'rock-climbing', 'technique'}), (1455117497, {'rock-climbing', 'camming-devices', 'maintenance'}), (1456882697, {'safety', 'rock-climbing', 'belaying', 'knots', 'rappelling'}), (1456937325, {'rock-climbing', 'ropes'}), (1459428479, {'terminology'}), (1459636808, {'rock-climbing', 'gear'}), (1460069665, {'recommendation-letter'}), (1460380140, {'supervision', 'privacy', 'nih'}), (1461967395, {'fees', 'united-states', 'financial-advisor', 'risk', 'investing'}), (1474909296, {'driveway'}), (1476719254, {'legal-issues', 'research-group', 'terminology'}), (1477082043, {'united-kingdom', 'employment', 'discrimination'}), (1480093755, {'peer-review', 'conflict-of-interest'}), (1480350516, {'social-media', 'academic-freedom', 'united-states'}), (1486767841, {'presentation', 'etiquette', 'ethics', 'conference'}), (1491780665, {'crawlspace', 'concrete'}), (1492105312, {'radiant-heating', 'basement'}), (1492106433, {'moisture', 'basement'}), (1492619872, {'planning-permission', 'inspection'}), (1492630284, {'code-compliance'}), (1494351715, {'dehumidifier', 'switch', 'condensation'}), (1495203686, {'basement', 'foundation', 'crack'}), (1495204259, {'shutoff', 'water'}), (1495578155, {'crawlspace', 'foundation'}), (1495638252, {'foundation', 'lawn'}), (1499261564, {'low-voltage', 'wiring'}), (1499969710, {'doors'}), (1505952800, {'multiway-switch', 'lighting'}), (1506469255, {'401k', 'united-states', '529-plan', 'income'}), (1506542163, {'contractors', 'remodeling'}), (1507064854, {'hardwood-floor'}), (1507212681, {'wiring', 'electrical'}), (1510002472, {'citation-style'}), (1513009820, {'funding', 'france'}), (1513191752, {'peer-review', 'open-access'}), (1513193357, {'chimney', 'fireplace'}), (1513282504, {'film-industry', 'distribution'}), (1517508297, {'retirement', 'united-states', 'comparison'}), (1519141557, {'rock-climbing', 'climbing-shoes'}), (1519848765, {'doors'}), (1528297729, {'children', 'wear', 'learning'}), (1533485950, {'windows'}), (1534536051, {'new-england', 'trails'}), (1534949436, {'plumbing', 'pest-control'}), (1543853319, {'war', 'play-time'}), (1543853319, {'war', 'play-time'}), (1543966311, {'gore-tex', 'rain-gear'}), (1547340200, {'plaster', 'leak'}), (1553525080, {'social-media', 'academic-life'}), (1557166417, {'air-travel', 'seating', 'jetblue'}), (1564415182, {'cats', 'feral'}), (1565635921, {'billing', 'massachusetts', 'united-states'}), (1574270498, {'hiring', 'title', 'hierarchy'})]\n",
      "\n",
      "USER 1106095 TAGS:\n",
      "[(1341223088, {'software', 'teaching'}), (1343056478, {'conference', 'networking'}), (1343647084, {'publications', 'journals', 'peer-review', 'conference'}), (1343650594, {'publications', 'journals'}), (1346750645, {'paperwork'}), (1349425429, {'publications', 'peer-review'}), (1353929506, {'responsibilities', 'contract'}), (1355405618, {'publications'}), (1359623571, {'job-search'}), (1359655998, {'publications', 'funding'}), (1360500458, {'publications', 'peer-review', 'application'}), (1360586056, {'poster', 'travel'}), (1361798551, {'united-kingdom', 'sexual-misconduct'}), (1362391150, {'seminars', 'etiquette'}), (1363091345, {'career-path', 'working-time', 'sabbatical'}), (1366622104, {'job-search', 'version-control'}), (1367225030, {'ethics', 'peer-review'}), (1370509865, {'copyright', 'creative-commons'}), (1371471877, {'assessment'}), (1375350804, {'writing-style', 'funding', 'writing'}), (1377078634, {'authorship'}), (1379871860, {'faculty-application', 'recommendation-letter'}), (1380631137, {'authorship'}), (1380821299, {'teaching'}), (1387804346, {'job-search'}), (1388146049, {'job-search', 'united-states', 'tenure-track'}), (1389975678, {'publications', 'open-access'}), (1392282649, {'job-search'}), (1394465484, {'cruising'}), (1394708555, {'repatriation', 'usa', 'health-insurance'}), (1394808223, {'united-kingdom', 'usa', 'taxes'}), (1395049854, {'telephone', 'usa'}), (1395138414, {'education', 'usa', 'children', 'repatriation'}), (1395264866, {'united-kingdom', 'citizenship', 'marriage', 'legal'}), (1395309775, {'television'}), (1395741049, {'united-kingdom', 'criminal-records', 'us-citizens'}), (1398807482, {'colleagues'}), (1401660590, {'publications'}), (1403272306, {'disreputable-publishers', 'open-access'}), (1403598266, {'gifts', 'etiquette', 'ethics'}), (1403964864, {'ethics', 'conflict-of-interest'}), (1406646659, {'software', 'copyright', 'graphics'}), (1407436529, {'teaching'}), (1407572885, {'teaching'}), (1410029421, {'postdocs', 'cv'}), (1410516513, {'work-life-balance', 'working-time', 'teaching'}), (1411051600, {'books', 'teaching'}), (1411055405, {'gender', 'sexual-misconduct', 'interpersonal-issues'}), (1411987941, {'syllabus', 'teaching'}), (1412794220, {'united-kingdom', 'health', 'workplace'}), (1412876949, {'gender', 'religious-issues', 'interpersonal-issues', 'ethnicity', 'reference-request'}), (1413557739, {'ethics'}), (1414341713, {'cheating', 'plagiarism'}), (1414343891, {'assessment', 'teaching', 'grading'}), (1414595557, {'funding'}), (1415015726, {'online-learning'}), (1415369795, {'presentation', 'software'}), (1418377606, {'legal-issues'}), (1418753861, {'writing-style', 'website'}), (1418754656, {'degree', 'masters', 'terminology'}), (1420991559, {'salary', 'funding', 'tuition'}), (1420997947, {'tips-and-tricks', 'sleeping'}), (1421004498, {'united-kingdom', 'working-visas'}), (1421004835, {'united-kingdom', 'working-visas'}), (1422525943, {'job-search', 'united-states', 'salary', 'career-path', 'government-institutes'}), (1422890167, {'reputation', 'publications', 'conference', 'computer-science'}), (1422983098, {'plagiarism'}), (1422986986, {'privacy', 'career-path'}), (1423059036, {'graduate-admissions', 'phd', 'united-states', 'canonical-question'}), (1423229504, {'plagiarism', 'ethics'}), (1426514198, {'education', 'working-visas', 'usa'}), (1427104079, {'authorship'}), (1427839634, {'otolaryngology', 'treatment', 'infection'}), (1427840696, {'micronutrients', 'nutrition'}), (1427892888, {'optometry'}), (1429979839, {'personal-name', 'authorship'}), (1430486657, {'commuter', 'bikeroutes'}), (1430672000, {'peer-review'}), (1430839436, {'united-states', 'international', 'united-kingdom', 'home-loan', 'mortgage'}), (1432486019, {'real-estate', 'united-states', 'mortgage', 'primary-residence'}), (1432634559, {'job-search', 'etiquette'}), (1433178274, {'driving-license', 'usa', 'us-citizens'}), (1433178445, {'terminology'}), (1434630323, {'backup-archiving', 'arxiv'}), (1436623288, {'recruiting'}), (1436891607, {'outward-appearance', 'ethics'}), (1441821819, {'bibliometrics'}), (1442155346, {'studs', 'lath-and-plaster', 'partition'}), (1447546386, {'lath-and-plaster', 'trim'}), (1448755184, {'electrical', 'rewire'}), (1454966636, {'backpacking', 'footwear'}), (1455045228, {'rock-climbing', 'technique'}), (1455117497, {'rock-climbing', 'camming-devices', 'maintenance'}), (1456882697, {'safety', 'rock-climbing', 'belaying', 'knots', 'rappelling'}), (1456937325, {'rock-climbing', 'ropes'}), (1459428479, {'terminology'}), (1459636808, {'rock-climbing', 'gear'}), (1460069665, {'recommendation-letter'}), (1460380140, {'supervision', 'privacy', 'nih'}), (1461967395, {'fees', 'united-states', 'financial-advisor', 'risk', 'investing'}), (1474909296, {'driveway'}), (1476719254, {'legal-issues', 'research-group', 'terminology'}), (1477082043, {'united-kingdom', 'employment', 'discrimination'}), (1480093755, {'peer-review', 'conflict-of-interest'}), (1480350516, {'social-media', 'academic-freedom', 'united-states'}), (1486767841, {'presentation', 'etiquette', 'ethics', 'conference'}), (1491780665, {'crawlspace', 'concrete'}), (1492105312, {'radiant-heating', 'basement'}), (1492106433, {'moisture', 'basement'}), (1492619872, {'planning-permission', 'inspection'}), (1492630284, {'code-compliance'}), (1494351715, {'dehumidifier', 'switch', 'condensation'}), (1495203686, {'basement', 'foundation', 'crack'}), (1495204259, {'shutoff', 'water'}), (1495578155, {'crawlspace', 'foundation'}), (1495638252, {'foundation', 'lawn'}), (1499261564, {'low-voltage', 'wiring'}), (1499969710, {'doors'}), (1505952800, {'multiway-switch', 'lighting'}), (1506469255, {'401k', 'united-states', '529-plan', 'income'}), (1506542163, {'contractors', 'remodeling'}), (1507064854, {'hardwood-floor'}), (1507212681, {'wiring', 'electrical'}), (1510002472, {'citation-style'}), (1513009820, {'funding', 'france'}), (1513191752, {'peer-review', 'open-access'}), (1513193357, {'chimney', 'fireplace'}), (1513282504, {'film-industry', 'distribution'}), (1517508297, {'retirement', 'united-states', 'comparison'}), (1519141557, {'rock-climbing', 'climbing-shoes'}), (1519848765, {'doors'}), (1528297729, {'children', 'wear', 'learning'}), (1533485950, {'windows'}), (1534536051, {'new-england', 'trails'}), (1534949436, {'plumbing', 'pest-control'}), (1543853319, {'war', 'play-time'}), (1543853319, {'war', 'play-time'}), (1543966311, {'gore-tex', 'rain-gear'}), (1547340200, {'plaster', 'leak'}), (1553525080, {'social-media', 'academic-life'}), (1557166417, {'air-travel', 'seating', 'jetblue'}), (1564415182, {'cats', 'feral'}), (1565635921, {'billing', 'massachusetts', 'united-states'}), (1574270498, {'hiring', 'title', 'hierarchy'})]\n",
      "\n",
      "USER 1532620 TAGS:\n",
      "[(1391025990, {'degree', 'phd'}), (1393956693, {'accreditation'}), (1393967449, {'teaching-assistant', 'france', 'academic-history'}), (1393972304, {'accreditation'}), (1397324300, {'ranking', 'academic-history'}), (1397541112, {'publications', 'online-publication', 'publishers'}), (1397869669, {'independent-researcher'}), (1399053515, {'publications', 'phd', 'academic-history', 'thesis'}), (1400264207, {'education', 'monarchy'}), (1400264207, {'education', 'monarchy'}), (1400990296, {'publications', 'books', 'publishers', 'editors'}), (1406870925, {'tutoring', 'academic-history', 'teaching'}), (1407359763, {'publications', 'copyright', 'books', 'publishers'}), (1407719630, {'harassment'}), (1409445936, {'church-fathers', 'creation', 'chronology', 'exegesis', 'genesis'}), (1410927910, {'cats', 'diet'}), (1411243957, {'desexing', 'cats'}), (1411782913, {'catholicism', 'clothing', 'religious-orders'}), (1411862326, {'aristotle', 'truth', 'aquinas', 'paradox'}), (1414435317, {'catholicism', 'protestantism', 'prayer'}), (1415128738, {'theology', 'kant'}), (1415424623, {'professorship', 'policy', 'legal-issues'}), (1415426135, {'theology', 'aquinas', 'critique-of-pure-reason', 'kant'}), (1415638445, {'interdisciplinary', 'phd', 'united-states'}), (1415746639, {'mathematicians', 'mathematics', 'gauss'}), (1416339904, {'quotes', 'hitler', 'john-f-kennedy'}), (1416339904, {'quotes', 'hitler', 'john-f-kennedy'}), (1416681708, {'pope', 'hitler', 'spain', 'religion', 'catholic-church'}), (1416842146, {'protestantism', 'apostolic-succession', 'papacy'}), (1416847250, {'apostolic-succession', 'lutheranism', 'anglicanism'}), (1416948388, {'apostolic-succession', 'anglicanism'}), (1418062543, {'evolution', 'biology'}), (1418244406, {'legal', 'loans'}), (1418872492, {'publications', 'books', 'citations', 'physics'}), (1420697963, {'france', 'germany', 'online-resource', 'thesis', 'italy'}), (1420854361, {'interdisciplinary', 'phd', 'united-states'}), (1421693691, {'masters', 'united-states'}), (1421710796, {'transcript-of-records'}), (1422728012, {'mathematics'}), (1423713836, {'cats', 'psychology', 'play', 'diet'}), (1423775825, {'graduate-admissions', 'phd', 'recommendation-letter'}), (1423947565, {'idolatry', 'st-thomas-aquinas', 'paul-apostle', 'romans', 'homosexuality'}), (1425150254, {'cats', 'biology', 'breeding'}), (1425309050, {'desexing', 'cats', 'behavior'}), (1425407028, {'debit-card', 'credit-card', 'visa'}), (1425411293, {'cats', 'leash-training'}), (1426189821, {'credit-card', 'online-payment'}), (1429148668, {'independent-researcher', 'reference-request'}), (1429351347, {'terminology', 'united-states'}), (1431720907, {'chargeback', 'credit-card'}), (1434965538, {'home', 'home-loan', 'first-time-home-buyer', 'fico-score'}), (1436499393, {'catholicism', 'ten-commandments', 'morality', 'name-of-jesus'}), (1437267564, {'archaeoastronomy', 'astronomy', 'ancient-greece'}), (1438446398, {'aristotle', 'virginity'}), (1439179999, {'antonyms'}), (1440218075, {'graduate-admissions', 'funding', 'ethics', 'soft-money'}), (1443671943, {'home-loan', 'repayment', 'mortgage'}), (1447025671, {'catholicism', 'schism', 'papacy'}), (1448692982, {'disability', 'learning'}), (1449032579, {'notation', 'mathematical-physics', 'physics'}), (1452281653, {'power', 'meter', 'circuit-breaker'}), (1452292888, {'causation', 'aristotle', 'aquinas', 'causality'}), (1453244524, {'credit-score', 'credit', 'fico-score'}), (1454011058, {'yeast'}), (1456361532, {'catholicism', 'membership', 'ecclesiology', 'baptism'}), (1458962548, {'thermodynamics', 'chemistry'}), (1459725778, {'protestantism', 'politics', 'united-states', 'judaism'}), (1460402533, {'oil', 'entomophagy', 'seasoning'}), (1462673920, {'software', 'midi'}), (1462830874, {'temperament', 'microtonality', 'intonation', 'pitch'}), (1463103545, {'experimental-physics', 'resource-recommendation', 'physics'}), (1463434884, {'celestial-mechanics', 'astronomy'}), (1463495581, {'funding', 'academic-history'}), (1463593539, {'terminology', 'philosophy-of-mathematics', 'logic', 'quantification', 'philosophy-of-logic'}), (1464204144, {'relativity-theory', 'nobel-prize'}), (1464412769, {'light', 'electromagnetism'}), (1464413790, {'magnetism', 'electricity', 'electromagnetism'}), (1464416104, {'education', 'magnetism', 'electricity', 'electromagnetism'}), (1466606972, {'relativity-theory', 'einstein'}), (1468514591, {'mathematical-physics', 'electromagnetism', 'electricity', 'physics'}), (1469321858, {'graduate-admissions', 'exams', 'diversity'}), (1469418744, {'catholicism', 'paul-apostle', 'exegesis', '2-corinthians'}), (1469418744, {'catholicism', 'paul-apostle', 'exegesis', '2-corinthians'}), (1469720882, {'magnetism', 'physics', 'maxwell', 'electricity', 'electromagnetism'}), (1469911271, {'terminology', 'electricity', 'electromagnetism'}), (1470092792, {'desexing', 'cats'}), (1470095992, {'desexing', 'cats'}), (1470521501, {'fugue', 'exercises', 'composition'}), (1471544318, {'descartes', 'history-of-philosophy'}), (1472060851, {'catholicism', 'philosophy', 'papacy', 'church-history', 'schism'}), (1472354805, {'knowledge'}), (1472354805, {'knowledge'}), (1473193134, {'number-theory'}), (1473465642, {'nominalism'}), (1474959082, {'joseph-husband-of-mary', 'virgin-mary', 'history'}), (1475354094, {'personal-care', 'bathroom'}), (1475539723, {'medieval', 'science-fiction-genre', 'history-of'}), (1477062937, {'catholicism', 'judaism', 'jews', 'mosaic-law', 'justification'}), (1477062937, {'catholicism', 'judaism', 'jews', 'mosaic-law', 'justification'}), (1478880263, {'catholicism', 'virginity', 'sacraments'}), (1480639959, {'recycling'}), (1481500980, {'publications', 'books', 'creative-commons'}), (1481728546, {'doi'}), (1482173554, {'cats', 'behavior'}), (1482176326, {'ethics', 'editors'}), (1482337974, {'anonymity', 'peer-review'}), (1483822113, {'units', 'physics'}), (1484406874, {'copyright', 'theft'}), (1484412188, {'contract', 'copyright', 'licensing', 'creative-commons'}), (1484415264, {'copyright', 'attribution'}), (1484519397, {'public-domain', 'copyright', 'licensing'}), (1485991093, {'musical-forms', 'modern-music', 'electronic-music'}), (1487737684, {'brahman', 'philosophy', 'adi-shankaracharya', 'atma'}), (1489109807, {'closed-source', 'statistics'}), (1490656621, {'potential'}), (1490839464, {'tomatoes', 'watering', 'drip-system', 'containers', 'irrigation'}), (1491599571, {'logic'}), (1492626581, {'print-on-demand', 'pages'}), (1493760011, {'feeding', 'cats'}), (1493777221, {'learning-resources', 'books', 'violin'}), (1494128637, {'creative-commons', 'copyright', 'license', 'open-access', 'publishability'}), (1494203974, {'scales', 'theory', 'modes'}), (1494543081, {'shrubs', 'desert', 'flowers', 'flowering', 'identification'}), (1494545984, {'desert', 'ground-cover', 'flowers', 'flowering', 'identification'}), (1494546111, {'shrubs', 'desert', 'flowers', 'flowering', 'identification'}), (1494546111, {'shrubs', 'desert', 'flowers', 'flowering', 'identification'}), (1494700093, {'irrigation', 'drip-system'}), (1494887130, {'fruit-trees', 'planting'}), (1495066193, {'trees', 'desert', 'dryness', 'drip-system'}), (1495066193, {'trees', 'desert', 'dryness', 'drip-system'}), (1495215261, {'irrigation'}), (1495302143, {'galileo', 'reference-request', 'quote'}), (1495312402, {'desert', 'tomatoes', 'blight', 'watering'}), (1495423445, {'myths', 'aristotle', 'monotheism'}), (1495423624, {'greek', 'christianity', 'religion', 'ancient-rome', 'greek-mythology'}), (1495423624, {'greek', 'christianity', 'religion', 'ancient-rome', 'greek-mythology'}), (1495470037, {'myths', 'philosophy-of-science', 'rhetoric'}), (1495558279, {'tomatoes', 'harvesting'}), (1499461305, {'language'}), (1499537002, {'aristotle', 'reference-request', 'averroes'}), (1501860327, {'print-on-demand'}), (1502053129, {'identification'}), (1504194532, {'baptism', 'sect', 'anabaptism', 'church-history'}), (1504829707, {'joseph', 'holy-family', 'art', 'virgin-mary'}), (1505149874, {'aristotle', 'reference-request'}), (1505149874, {'aristotle', 'reference-request'}), (1505843726, {'vitamins', 'vegan'}), (1506964484, {'audacity'}), (1509241747, {'recordings', 'engineering', 'audacity', 'request', 'production'}), (1511799753, {'third-party', 'repair', 'display', 'macbook-pro'}), (1515725927, {'monarchy', 'catholic-church', 'royalty'}), (1516146132, {'monarchy', 'catholic-church', 'papacy'}), (1517077887, {'euclidean-geometry', 'mathematical-logic', 'mathematics'}), (1517267294, {'terminology', 'mathematics'}), (1517888532, {'mathematical-logic', 'terminology', 'mathematics'}), (1517935259, {'citations', 'google-scholar'}), (1519612552, {'ios', 'playlist', 'url'}), (1520825182, {'salad-dressing', 'coconut-oil'}), (1521765173, {'organic'}), (1521914296, {'greeks', 'history-of-logic', 'history-of-philosophy', 'logic', 'empiricism'}), (1521914351, {'ancient-greece'}), (1523074903, {'eastern-orthodox', 'celibacy', 'marriage'}), (1523304224, {'yeast', 'leavening', 'baking-powder'}), (1523304224, {'yeast', 'leavening', 'baking-powder'}), (1523918586, {'desert', 'grubs', 'watering'}), (1524075642, {'greek', 'marriage', 'ephesians', 'latin-vulgate', 'grammar'}), (1526405865, {'thermodynamics', 'energy', 'reference-request'}), (1527091786, {'virginity', 'lds', 'children', 'marriage'}), (1527093377, {'diet', 'health', 'history', 'plant-based', 'society'}), (1527273120, {'exchange', 'atms', 'europe'}), (1527381296, {'preprint', 'monograph'}), (1527881573, {'preprint', 'doi'}), (1534107108, {'foia', 'united-states', 'marriage'}), (1534202147, {'iphone', 'wifi-calling'}), (1534202147, {'iphone', 'wifi-calling'}), (1534527919, {'acronyms', 'terminology'}), (1535478359, {'mathematical-physics', 'astronomy', 'physics'}), (1536290935, {'us-supreme-court', 'united-states', 'precedent'}), (1536355376, {'intellectual-property', 'court-records', 'united-states', 'copyright', 'us-supreme-court'}), (1536356008, {'intellectual-property', 'secret'}), (1536361492, {'political-theory', 'form-of-government', 'united-states', 'monarchy', 'democracy'}), (1536429707, {'political-theory', 'form-of-government', 'united-states', 'democracy'}), (1538416608, {'aristotle', 'souls', 'philosophy-of-biology'}), (1538416792, {'medicine', 'terminology', 'biology'}), (1545338792, {'evolutionary-linguistics', 'evolution', 'vocabulary'}), (1545338792, {'evolutionary-linguistics', 'evolution', 'vocabulary'}), (1547337122, {'italian-cuisine', 'hominy', 'polenta', 'cornmeal'}), (1548871521, {'political-theory', 'terminology', 'political-system', 'form-of-government', 'history'}), (1549405275, {'catholicism', 'souls', 'papal-infallibility', 'dogma', 'nature-of-man'}), (1550595838, {'iphone', 'unix', 'file-transfer'}), (1551219962, {'freedom-of-speech', 'united-states', 'first-amendment'}), (1551223190, {'freedom-of-speech', 'first-amendment', 'religion', 'united-states', 'constitutional-law'}), (1551655608, {'short-stories', 'story-identification'}), (1553227997, {'us-supreme-court', 'united-states'}), (1553376059, {'printing', 'print-on-demand', 'self-publishing'}), (1554174887, {'raw', 'oats'}), (1556059839, {'juicing', 'citrus', 'equipment', 'juice'}), (1556117580, {'catharism', 'jansenism', 'marriage'}), (1558021185, {'catholicism', 'religious-life', 'spirituality', 'sexuality', 'spiritual-theology'}), (1560547926, {'st-thomas-aquinas'}), (1563056484, {'catholicism', 'marriage', 'heresy', 'dubia-cardinals', 'morality'}), (1564002672, {'catholicism', 'marriage', 'heresy', 'morality', 'adultery'}), (1564373569, {'citrus', 'wine', 'fermentation'}), (1565038463, {'hunting', 'cats'}), (1565148990, {'ingredient-selection', 'raw', 'vegan', 'nutrient-composition'}), (1565148990, {'ingredient-selection', 'raw', 'vegan', 'nutrient-composition'}), (1565149214, {'nutritional-deficiency', 'nutrition', 'veganism', 'protein', 'rawfood-diet'}), (1566253653, {'onomastics', 'etymology', 'mary', 'hebrew'}), (1570061545, {'mathematicians', 'number-theory', 'reference-request', 'mathematics'}), (1570243569, {'cauchy', 'mathematics', 'mathematicians', 'calculus', 'real-analysis'}), (1573964431, {'ancient-rome', 'architecture', 'reference'}), (1574382508, {'raw', 'seeds'}), (1575774427, {'mathematics', 'relativity-theory', 'einstein', 'reference-request', 'physics'}), (1575992696, {'food-preservation', 'coffee'}), (1576886956, {'descartes', 'foundations-of-mathematics', 'philosophy-of-mathematics'}), (1589391899, {'mathematics'}), (1594504111, {'plant-based', 'medicine', 'scientific-studies'}), (1597688710, {'terminology', 'electricity', 'physics'}), (1610495581, {'verse-identification', 'civil-government'}), (1618544848, {'chords', 'intervals', 'theory', 'history'}), (1621021586, {'hamlet', 'religion', 'william-shakespeare', 'wording-choice'}), (1642647258, {'virginity', 'gospel-of-matthew', 'jerome', 'perpetual-virginity', 'virgin-mary'}), (1644204458, {'plant-based', 'omnivorous-diet', 'nutritional-deficiency', 'nutrition'}), (1644602289, {'pitch', 'audacity', 'playback'}), (1644688528, {'nutritional-deficiency', 'vitamins-and-minerals', 'nutrition', 'recipe-request', 'veganism'}), (1652390870, {'academic-history', 'history'}), (1657413198, {'trees', 'desert', 'identification', 'evergreens'})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# put everything together\n",
    "user_tags_df = pd.concat([\n",
    "    pd.read_json('PIR_data/answer_retrieval/train/subset_data.jsonl', lines=True),\n",
    "    pd.read_json('PIR_data/answer_retrieval/val/subset_data.jsonl', lines=True),\n",
    "    pd.read_json('PIR_data/answer_retrieval/test/subset_data.jsonl', lines=True)\n",
    "])[['id', 'user_id', 'timestamp', 'tags']]\n",
    "user_tags_df.columns = ['qid', 'user_id', 'timestamp', 'tags']\n",
    "user_tags_df['timestamp'] = user_tags_df[\"timestamp\"].astype(int) // 10**9\n",
    "user_tags_df['tags'] = user_tags_df['tags'].apply(set)\n",
    "\n",
    "display(user_tags_df.head(3))\n",
    "\n",
    "# Build user_data dictionary\n",
    "USER_TAGS = {}\n",
    "for user, group in user_tags_df.groupby(\"user_id\"):\n",
    "    # list of tuples (timestamp, tags), sorted by timestamp\n",
    "    USER_TAGS[user] = sorted(zip(group[\"timestamp\"], group[\"tags\"]), key=lambda x: x[0])\n",
    "\n",
    "### SAVE\n",
    "joblib.dump(USER_TAGS, './index_sepqa/user_tags_subset.joblib')\n",
    "\n",
    "users = user_tags_df.head(3)['user_id'].values\n",
    "for user in users:\n",
    "    print(f\"USER {user} TAGS:\")\n",
    "    print(USER_TAGS[user])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER = 1106095 , timestamp = 1391025990 TAGS: {'publications', 'paperwork', 'responsibilities', 'contract', 'networking', 'sabbatical', 'faculty-application', 'etiquette', 'creative-commons', 'seminars', 'conference', 'recommendation-letter', 'teaching', 'software', 'working-time', 'sexual-misconduct', 'copyright', 'poster', 'career-path', 'authorship', 'job-search', 'version-control', 'tenure-track', 'writing', 'travel', 'united-kingdom', 'writing-style', 'peer-review', 'assessment', 'united-states', 'funding', 'journals', 'open-access', 'ethics', 'application'}\n",
      "USER = 1106095 , timestamp = 1391025990 TAGS: {'publications', 'paperwork', 'responsibilities', 'contract', 'networking', 'sabbatical', 'faculty-application', 'etiquette', 'creative-commons', 'seminars', 'conference', 'recommendation-letter', 'teaching', 'software', 'working-time', 'sexual-misconduct', 'copyright', 'poster', 'career-path', 'authorship', 'job-search', 'version-control', 'tenure-track', 'writing', 'travel', 'united-kingdom', 'writing-style', 'peer-review', 'assessment', 'united-states', 'funding', 'journals', 'open-access', 'ethics', 'application'}\n",
      "USER = 1532620 , timestamp = 1391025990 TAGS: {'degree', 'phd'}\n"
     ]
    }
   ],
   "source": [
    "# LOAD\n",
    "USER_TAGS = joblib.load('./index_sepqa/user_tags_subset.joblib')\n",
    "\n",
    "def get_user_tags(user_id, timestamp):\n",
    "    tags = set()\n",
    "    for ts, user_tags in USER_TAGS[user_id]:\n",
    "        if ts <= timestamp:\n",
    "            tags = tags.union(user_tags)\n",
    "        # the ts are sorted, so we can break when we reach the timestamp\n",
    "        else:\n",
    "            break\n",
    "    return tags\n",
    "\n",
    "t = 1391025990\n",
    "for user in users:\n",
    "    print(f\"USER = {user} , timestamp = {t} TAGS: {get_user_tags(user, t)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking pipeline with query expansion\n",
    "\n",
    "`PIPELINE = BM25 % 100 >> expand_query >> BiEncoder`\n",
    "\n",
    "We define the function that expand the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE EXPANSION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query_unprocessed</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are CNRS research units and how are they ...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qid                                  query_unprocessed  \\\n",
       "0  academia_100305  What are CNRS research units and how are they ...   \n",
       "0  academia_100305  What are CNRS research units and how are they ...   \n",
       "0  academia_100305  What are CNRS research units and how are they ...   \n",
       "\n",
       "   user_id   timestamp                                              query  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER EXPANSION\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query_expanded</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are the different types of research unit...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are the different types of research unit...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academia_100305</td>\n",
       "      <td>What are the different types of research unit...</td>\n",
       "      <td>1106095</td>\n",
       "      <td>1513009820</td>\n",
       "      <td>cnr research unit staf centr nation de la rech...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qid                                     query_expanded  \\\n",
       "0  academia_100305   What are the different types of research unit...   \n",
       "0  academia_100305   What are the different types of research unit...   \n",
       "0  academia_100305   What are the different types of research unit...   \n",
       "\n",
       "   user_id   timestamp                                              query  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  \n",
       "0  1106095  1513009820  cnr research unit staf centr nation de la rech...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _expand_query(df, pipeline, generation_args):\n",
    "    \"\"\"\n",
    "    Expand queries with user tags\n",
    "\n",
    "    used as argument of pyterrier.apply.by_query()\n",
    "        => the input is a dataframe for one query at at time\n",
    "    \"\"\"\n",
    "    # take just the first of everything, since we will use it for pt.apply.by_query()\n",
    "    # we receive an input dataframe that contains only one query\n",
    "    # in particular in our case the 100 rows given by BM25 % 100\n",
    "    user_id = df['user_id'].iloc[0]\n",
    "    timestamp = df['timestamp'].iloc[0]\n",
    "    tags = get_user_tags(user_id, timestamp)\n",
    "    user_tags_str = \", \".join(tags)\n",
    "    query = df['query_unprocessed'].iloc[0]\n",
    "    prompt = f\"\"\"\n",
    "        Given the user interests as comma separated values and the query,\n",
    "        provide an expanded version of the query with personalized interests.\n",
    "        Just say New Query: and put the generated query. Do non mention anything else.\n",
    "        Keywords: {user_tags_str} Query: {query}\n",
    "    \"\"\"\n",
    "    prompt = re.sub(r\"\\s+\", \" \", prompt)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    output = pipeline(messages, **generation_args)\n",
    "    expanded_query = output[0]['generated_text']\n",
    "    expand_query = re.sub(r\"New Query: \", \"\", expanded_query)\n",
    "    df['query_unprocessed'] = expand_query\n",
    "    df = df.rename(columns={'query_unprocessed': 'query_expanded'})\n",
    "    return df\n",
    "\n",
    "### EXAMPLE\n",
    "sample_df = pd.concat([train_queries.head(1)]*3)\n",
    "print(\"BEFORE EXPANSION\")\n",
    "display(sample_df)\n",
    "print(\"AFTER EXPANSION\")\n",
    "sample_df = _expand_query(sample_df, pipe, generation_args)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### REPORTED FROM PREVIOUS NOTEBOOK\n",
    "## GET SCORES BIENCODER\n",
    "\n",
    "def _get_dense_scores(df, FAISS_INDEX, biencoder_model, text_field='query_unprocessed', k=1000):\n",
    "    \"\"\"\n",
    "    get cosine similarity score with a biencoder model, with FAISS FlatIndex\n",
    "\n",
    "    used as argument of pyterrier.apply.doc_score()\n",
    "        =>  the input is a ranked documents dataframe (batch), by query\n",
    "            the output are the scores for each document in the batch\n",
    "    \"\"\"\n",
    "    if not all(df['qid'] == df['qid'].iloc[0]):\n",
    "        assert \"Not all qids in the batch are equal\"\n",
    "    # get the query unprocessed text\n",
    "    query_text = df[text_field].iloc[0]\n",
    "    # get the query embedding\n",
    "    query_embedding = biencoder_model.encode(query_text).astype('float32')\n",
    "    query_embedding = query_embedding / np.linalg.norm(query_embedding) # normalize for cosine similarity\n",
    "\n",
    "    # if we are reranking\n",
    "    if 'docid' in df.columns:\n",
    "        # select the retrieved documents\n",
    "        filter_ids = df['docid'].values\n",
    "        id_selector = faiss.IDSelectorArray(np.array(filter_ids, dtype=np.int64))\n",
    "        search_params = faiss.SearchParametersIVF(sel=id_selector)\n",
    "        # rerank them\n",
    "        k = len(filter_ids)\n",
    "        distances, indices = FAISS_INDEX.search(np.array([query_embedding]), k, params=search_params)\n",
    "    else:\n",
    "        distances, indices = FAISS_INDEX.search(np.array([query_embedding]), k)\n",
    "\n",
    "    # mapping {docid: score}\n",
    "    score_mapping = {docid: score for docid, score in zip(indices[0], distances[0])}\n",
    "    # get the scores in the original order (same as the input docids)\n",
    "    scores_original_order = [score_mapping[docid] for docid in df['docid']]\n",
    "    return scores_original_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIRST STAGE\n",
    "path = \"./index_sepqa/index_bm25/data.properties\"\n",
    "bm25_index = pt.IndexFactory.of(path)\n",
    "bm25 = pt.terrier.Retriever(\n",
    "    bm25_index, \n",
    "    wmodel=\"BM25\", \n",
    "    controls={'c': 1.0, 'bm25.k_1': 2.5},\n",
    "    properties={\"termpipelines\": \"\"},\n",
    ")\n",
    "\n",
    "### SECOND STAGE\n",
    "biencoder_model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "index_path = \"./index_sepqa/MiniLM_faiss_IndexFlatIP.index\"\n",
    "FAISS_INDEX = faiss.read_index(index_path)\n",
    "get_dense_score = partial(_get_dense_scores, FAISS_INDEX=FAISS_INDEX, \n",
    "                          biencoder_model=biencoder_model, text_field='query_expanded') ### CHANGE TO query_expanded, not text unprocessed\n",
    "bi_enc = pt.apply.doc_score(get_dense_score, batch_size=64)\n",
    "\n",
    "### QUERY EXPANSION\n",
    "expand_query = partial(_expand_query, pipeline=pipe, generation_args=generation_args)\n",
    "query_expander = pt.apply.by_query(expand_query)\n",
    "\n",
    "### PIPELINE\n",
    "pipeline_QE = bm25 % 100 >> query_expander >> bi_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment duration : 1274.12 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>nDCG@3</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>R@100</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25_QE_MiniLM</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.891</td>\n",
       "      <td>12740.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name    P@1   P@3  nDCG@3  nDCG@10  R@100  AP@100        mrt\n",
       "0  BM25_QE_MiniLM  0.857  0.31   0.898    0.902  0.969   0.891  12740.013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# put it just for the seeing all of them here\n",
    "metrics = [P@1, P@3, nDCG@3, nDCG@10, R@100, MAP@100, 'mrt']\n",
    "save_dir = \"./experiments/query_expansion/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "SAVE_MODE = \"reuse\" # reuse warn overwrite error\n",
    "\n",
    "t0 = time.time()\n",
    "results = pt.Experiment(\n",
    "    [pipeline_QE],\n",
    "    val_queries,\n",
    "    val_qrels,\n",
    "    eval_metrics=metrics,\n",
    "    names=[\"BM25_QE_MiniLM\"],\n",
    "    save_dir=save_dir,\n",
    "    save_mode=SAVE_MODE,\n",
    ")\n",
    "\n",
    "if SAVE_MODE == \"overwrite\":\n",
    "    print(\"Experiment duration :\", round(time.time()-t0, 2), \"seconds\")\n",
    "    # Experiment duration : 1274.12 seconds\n",
    "\n",
    "    path = \"./experiments/query_expansion/results_val_BM25_QE_MiniLM.csv\"\n",
    "    results.to_csv(path)\n",
    "\n",
    "\n",
    "display(results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method was implemented as a straightforward approach to personalize a query. However, it’s evident that utilizing LLMs solely for query rewriting is an inefficient use of resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir-project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
